L'output de model.fit(test_img, epochs=10)
1/8 [==>...........................] - ETA: 0s - loss: 0.6881 - accuracy: 0.5312
2/8 [======>.......................] - ETA: 7s - loss: 0.6796 - accuracy: 0.5781
3/8 [==========>...................] - ETA: 7s - loss: 0.6621 - accuracy: 0.6042
4/8 [==============>...............] - ETA: 6s - loss: 0.6276 - accuracy: 0.6484
5/8 [=================>............] - ETA: 5s - loss: 0.5996 - accuracy: 0.7063
6/8 [=====================>........] - ETA: 3s - loss: 0.5919 - accuracy: 0.7135
7/8 [=========================>....] - ETA: 1s - loss: 0.5868 - accuracy: 0.7232
8/8 [==============================] - ETA: 0s - loss: 0.5691 - accuracy: 0.7431
8/8 [==============================] - 15s 2s/step - loss: 0.5691 - accuracy: 0.7431
Epoch 2/10
1/8 [==>...........................] - ETA: 0s - loss: 0.4932 - accuracy: 0.7500
2/8 [======>.......................] - ETA: 7s - loss: 0.4823 - accuracy: 0.7812
3/8 [==========>...................] - ETA: 7s - loss: 0.4770 - accuracy: 0.7812
4/8 [==============>...............] - ETA: 6s - loss: 0.4930 - accuracy: 0.7734
5/8 [=================>............] - ETA: 5s - loss: 0.4835 - accuracy: 0.7875
6/8 [=====================>........] - ETA: 3s - loss: 0.4876 - accuracy: 0.7865
7/8 [=========================>....] - ETA: 1s - loss: 0.4837 - accuracy: 0.7991
8/8 [==============================] - 14s 2s/step - loss: 0.4774 - accuracy: 0.8024
Epoch 3/10
1/8 [==>...........................] - ETA: 0s - loss: 0.4696 - accuracy: 0.8438
2/8 [======>.......................] - ETA: 5s - loss: 0.4389 - accuracy: 0.8906
3/8 [==========>...................] - ETA: 6s - loss: 0.4508 - accuracy: 0.8333
4/8 [==============>...............] - ETA: 5s - loss: 0.4642 - accuracy: 0.8125
5/8 [=================>............] - ETA: 4s - loss: 0.4477 - accuracy: 0.8375
6/8 [=====================>........] - ETA: 3s - loss: 0.4417 - accuracy: 0.8385
7/8 [=========================>....] - ETA: 1s - loss: 0.4526 - accuracy: 0.8214
8/8 [==============================] - 13s 2s/step - loss: 0.4564 - accuracy: 0.8182
Epoch 4/10
1/8 [==>...........................] - ETA: 0s - loss: 0.4154 - accuracy: 0.8750
2/8 [======>.......................] - ETA: 5s - loss: 0.3952 - accuracy: 0.9219
3/8 [==========>...................] - ETA: 6s - loss: 0.4122 - accuracy: 0.8750
4/8 [==============>...............] - ETA: 5s - loss: 0.4383 - accuracy: 0.8438
5/8 [=================>............] - ETA: 4s - loss: 0.4620 - accuracy: 0.8188
6/8 [=====================>........] - ETA: 3s - loss: 0.4566 - accuracy: 0.8333
7/8 [=========================>....] - ETA: 1s - loss: 0.4520 - accuracy: 0.8393
8/8 [==============================] - 15s 2s/step - loss: 0.4430 - accuracy: 0.8458
Epoch 5/10
1/8 [==>...........................] - ETA: 0s - loss: 0.4150 - accuracy: 0.8438
2/8 [======>.......................] - ETA: 9s - loss: 0.4359 - accuracy: 0.8281
3/8 [==========>...................] - ETA: 8s - loss: 0.4452 - accuracy: 0.8438
4/8 [==============>...............] - ETA: 8s - loss: 0.4243 - accuracy: 0.8672
5/8 [=================>............] - ETA: 6s - loss: 0.4327 - accuracy: 0.8562
6/8 [=====================>........] - ETA: 4s - loss: 0.4267 - accuracy: 0.8646
7/8 [=========================>....] - ETA: 2s - loss: 0.4311 - accuracy: 0.8571
8/8 [==============================] - 19s 2s/step - loss: 0.4281 - accuracy: 0.8656
Epoch 6/10
1/8 [==>...........................] - ETA: 0s - loss: 0.4438 - accuracy: 0.8125
2/8 [======>.......................] - ETA: 6s - loss: 0.4247 - accuracy: 0.8594
3/8 [==========>...................] - ETA: 7s - loss: 0.4093 - accuracy: 0.8750
4/8 [==============>...............] - ETA: 6s - loss: 0.4145 - accuracy: 0.8594
5/8 [=================>............] - ETA: 5s - loss: 0.4070 - accuracy: 0.8687
6/8 [=====================>........] - ETA: 3s - loss: 0.4085 - accuracy: 0.8698
7/8 [=========================>....] - ETA: 1s - loss: 0.4099 - accuracy: 0.8705
8/8 [==============================] - 15s 2s/step - loss: 0.4130 - accuracy: 0.8735
Epoch 7/10
1/8 [==>...........................] - ETA: 0s - loss: 0.4270 - accuracy: 0.8750
2/8 [======>.......................] - ETA: 5s - loss: 0.3868 - accuracy: 0.9219
3/8 [==========>...................] - ETA: 6s - loss: 0.3895 - accuracy: 0.9062
4/8 [==============>...............] - ETA: 5s - loss: 0.3903 - accuracy: 0.9141
5/8 [=================>............] - ETA: 4s - loss: 0.3978 - accuracy: 0.9000
6/8 [=====================>........] - ETA: 3s - loss: 0.3963 - accuracy: 0.9062
7/8 [=========================>....] - ETA: 1s - loss: 0.3932 - accuracy: 0.9018
8/8 [==============================] - 14s 2s/step - loss: 0.3906 - accuracy: 0.9051
Epoch 8/10
1/8 [==>...........................] - ETA: 0s - loss: 0.4068 - accuracy: 0.9062
2/8 [======>.......................] - ETA: 5s - loss: 0.3880 - accuracy: 0.9375
3/8 [==========>...................] - ETA: 6s - loss: 0.3730 - accuracy: 0.9479
4/8 [==============>...............] - ETA: 5s - loss: 0.3819 - accuracy: 0.9375
5/8 [=================>............] - ETA: 4s - loss: 0.3767 - accuracy: 0.9312
6/8 [=====================>........] - ETA: 3s - loss: 0.3767 - accuracy: 0.9271
7/8 [=========================>....] - ETA: 1s - loss: 0.3759 - accuracy: 0.9330
8/8 [==============================] - 13s 2s/step - loss: 0.3806 - accuracy: 0.9249
Epoch 9/10
1/8 [==>...........................] - ETA: 0s - loss: 0.4260 - accuracy: 0.8750
2/8 [======>.......................] - ETA: 5s - loss: 0.4024 - accuracy: 0.8750
3/8 [==========>...................] - ETA: 6s - loss: 0.3985 - accuracy: 0.8854
4/8 [==============>...............] - ETA: 5s - loss: 0.3843 - accuracy: 0.9141
5/8 [=================>............] - ETA: 4s - loss: 0.3732 - accuracy: 0.9312
6/8 [=====================>........] - ETA: 3s - loss: 0.3687 - accuracy: 0.9375
7/8 [=========================>....] - ETA: 1s - loss: 0.3663 - accuracy: 0.9464
8/8 [==============================] - 13s 2s/step - loss: 0.3709 - accuracy: 0.9407
Epoch 10/10
1/8 [==>...........................] - ETA: 0s - loss: 0.3517 - accuracy: 0.9688
2/8 [======>.......................] - ETA: 5s - loss: 0.3469 - accuracy: 0.9688
3/8 [==========>...................] - ETA: 6s - loss: 0.3482 - accuracy: 0.9583
4/8 [==============>...............] - ETA: 5s - loss: 0.3546 - accuracy: 0.9453
5/8 [=================>............] - ETA: 4s - loss: 0.3505 - accuracy: 0.9563
6/8 [=====================>........] - ETA: 3s - loss: 0.3496 - accuracy: 0.9531
7/8 [=========================>....] - ETA: 1s - loss: 0.3505 - accuracy: 0.9554
8/8 [==============================] - 13s 2s/step - loss: 0.3589 - accuracy: 0.9407

Loss assez elevé... Peut-être bidouiller la learning rate ou le batch_size ? 

Les predictions de probability_model.predict(test_img) :

predictions : [[0.2839437  0.7160563 ]
 [0.27072093 0.72927904]
 [0.73038834 0.26961166]
 [0.7303438  0.26965612]
 [0.26899192 0.7310081 ]
 [0.73105854 0.26894143]
 [0.2714798  0.7285202 ]
 [0.557228   0.4427719 ]
 [0.26895314 0.73104686]
 [0.72634465 0.27365535]
 [0.5004177  0.4995823 ]
 [0.26903716 0.7309629 ]
 [0.2693222  0.7306778 ]
 [0.26896447 0.73103553]
 [0.72506917 0.27493083]
 [0.26894695 0.73105305]
 [0.2690276  0.73097235]
 [0.26903144 0.73096853]
 [0.26903573 0.73096424]
 [0.26912332 0.7308767 ]
 [0.26923695 0.730763  ]
 [0.27096748 0.7290326 ]
 [0.27057108 0.72942895]
 [0.26946133 0.7305387 ]
 [0.26950052 0.7304995 ]
 [0.7310581  0.2689419 ]
 [0.27512535 0.7248746 ]
 [0.26909533 0.7309047 ]
 [0.72873485 0.27126518]
 [0.26897    0.7310299 ]
 [0.26895654 0.73104346]
 [0.27230653 0.72769356]
 [0.2689512  0.7310488 ]
 [0.49905932 0.5009407 ]
 [0.26894695 0.73105305]
 [0.27529615 0.72470385]
 [0.5000415  0.49995852]
 [0.28506544 0.7149346 ]
 [0.27294612 0.7270539 ]
 [0.7305247  0.26947528]
 [0.2689459  0.7310541 ]
 [0.2689642  0.73103577]
 [0.2690276  0.73097235]
 [0.268992   0.731008  ]
 [0.50001913 0.49998093]
 [0.73047775 0.26952228]
 [0.27128497 0.72871506]
 [0.2690138  0.73098624]
 [0.26894453 0.73105544]
 [0.73105603 0.26894394]
 [0.2712817  0.7287183 ]
 [0.34337327 0.6566267 ]
 [0.29285827 0.7071417 ]
 [0.73105854 0.26894146]
 [0.27436888 0.7256311 ]
 [0.7310364  0.26896358]
 [0.72731537 0.27268466]
 [0.2692588  0.7307412 ]
 [0.2694915  0.73050857]
 [0.2690276  0.73097235]
 [0.26958779 0.73041224]
 [0.5814934  0.4185066 ]
 [0.26914543 0.7308545 ]
 [0.27475318 0.72524685]
 [0.26991656 0.73008347]
 [0.26906088 0.7309391 ]
 [0.26897585 0.73102415]
 [0.27069998 0.7293    ]
 [0.7310567  0.26894325]
 [0.7309305  0.26906946]
 [0.27469957 0.7253004 ]
 [0.27095848 0.7290416 ]
 [0.26911244 0.7308876 ]
 [0.7310562  0.26894388]
 [0.49372095 0.50627905]
 [0.2697305  0.73026943]
 [0.5000415  0.49995852]
 [0.2702676  0.7297324 ]
 [0.7310586  0.26894143]
 [0.26894483 0.73105514]
 [0.26902094 0.730979  ]
 [0.7310586  0.26894143]
 [0.719014   0.28098607]
 [0.2692978  0.7307023 ]
 [0.7309999  0.2690001 ]
 [0.2699413  0.73005867]
 [0.27121317 0.7287869 ]
 [0.6840681  0.31593192]
 [0.2691297  0.7308703 ]
 [0.283637   0.716363  ]
 [0.7307239  0.26927608]
 [0.5189068  0.48109323]
 [0.7310586  0.26894143]
 [0.72963834 0.27036166]
 [0.26954037 0.7304596 ]
 [0.26894873 0.7310512 ]
 [0.73064244 0.26935762]
 [0.26898345 0.7310166 ]
 [0.4912815  0.50871855]
 [0.47518355 0.52481645]
 [0.7143799  0.28562015]
 [0.2691411  0.7308589 ]
 [0.26894143 0.7310586 ]
 [0.5477791  0.4522209 ]
 [0.27244282 0.7275572 ]
 [0.2694584  0.73054165]
 [0.2691831  0.7308169 ]
 [0.27012622 0.7298738 ]
 [0.71912766 0.28087234]
 [0.7310468  0.26895317]
 [0.27025285 0.7297471 ]
 [0.73015964 0.26984033]
 [0.73104995 0.26895007]
 [0.2690119  0.7309881 ]
 [0.26894784 0.7310521 ]
 [0.7301838  0.26981622]
 [0.7278676  0.2721324 ]
 [0.43343455 0.56656545]
 [0.2696125  0.7303875 ]
 [0.2695205  0.73047954]
 [0.71990275 0.28009728]
 [0.26914594 0.73085403]
 [0.73044485 0.26955518]
 [0.26999158 0.73000836]
 [0.2694181  0.730582  ]
 [0.2690138  0.73098624]
 [0.5016069  0.49839306]
 [0.26901096 0.73098904]
 [0.270561   0.72943896]
 [0.2700607  0.72993934]
 [0.27451554 0.7254845 ]
 [0.26899227 0.7310077 ]
 [0.26913062 0.7308694 ]
 [0.2689431  0.7310569 ]
 [0.73105854 0.26894146]
 [0.7301897  0.26981035]
 [0.26897585 0.73102415]
 [0.2690276  0.73097235]
 [0.270964   0.729036  ]
 [0.26911733 0.7308827 ]
 [0.49385944 0.50614053]
 [0.26901415 0.7309859 ]
 [0.29961094 0.70038897]
 [0.7301893  0.26981068]
 [0.5512375  0.44876245]
 [0.7310585  0.26894152]
 [0.26894784 0.7310521 ]
 [0.26900122 0.7309987 ]
 [0.2689578  0.73104215]
 [0.26921114 0.7307888 ]
 [0.6564231  0.34357694]
 [0.5000005  0.49999952]
 [0.26897368 0.73102635]
 [0.2693615  0.73063856]
 [0.7310586  0.26894143]
 [0.7310586  0.26894143]
 [0.71557456 0.28442547]
 [0.26901916 0.7309809 ]
 [0.7308387  0.26916125]
 [0.268982   0.73101795]
 [0.2690988  0.7309011 ]
 [0.7305864  0.26941362]
 [0.73003554 0.26996446]
 [0.7285158  0.27148423]
 [0.2694916  0.7305084 ]
 [0.2689642  0.73103577]
 [0.26992685 0.73007315]
 [0.5002377  0.49976224]
 [0.73077685 0.2692231 ]
 [0.5830563  0.4169438 ]
 [0.2689578  0.73104215]
 [0.49871394 0.5012861 ]
 [0.7308934  0.26910657]
 [0.70461404 0.29538596]
 [0.53428626 0.4657138 ]
 [0.729539   0.27046102]
 [0.72737056 0.2726295 ]
 [0.7304664  0.26953354]
 [0.27070192 0.72929806]
 [0.7230123  0.2769877 ]
 [0.7238742  0.27612585]
 [0.7287228  0.27127725]
 [0.26911744 0.7308825 ]
 [0.27009556 0.7299045 ]
 [0.73105854 0.26894143]
 [0.73085284 0.2691472 ]
 [0.49904746 0.50095254]
 [0.2707418  0.7292582 ]
 [0.7309409  0.26905915]
 [0.72749686 0.27250314]
 [0.26936576 0.7306343 ]
 [0.26933536 0.7306646 ]
 [0.73105603 0.26894394]
 [0.7257485  0.27425155]
 [0.73044443 0.2695555 ]
 [0.2694729  0.7305271 ]
 [0.5000005  0.49999952]
 [0.4999924  0.5000076 ]
 [0.53341997 0.4665801 ]
 [0.26900098 0.730999  ]
 [0.6068986  0.39310148]
 [0.2689849  0.731015  ]
 [0.27138105 0.728619  ]
 [0.26897433 0.7310256 ]
 [0.26927313 0.7307269 ]
 [0.31711358 0.6828864 ]
 [0.43343455 0.56656545]
 [0.27256528 0.7274347 ]
 [0.73104995 0.26895007]
 [0.7192044  0.28079557]
 [0.26965833 0.7303417 ]
 [0.72371185 0.27628812]
 [0.2705445  0.7294555 ]
 [0.7300465  0.26995352]
 [0.73075193 0.26924816]
 [0.26896358 0.7310364 ]
 [0.27009556 0.7299045 ]
 [0.7310572  0.2689428 ]
 [0.7310586  0.26894143]
 [0.26986486 0.7301352 ]
 [0.2706158  0.7293842 ]
 [0.73075193 0.26924816]
 [0.2689459  0.7310541 ]
 [0.7308977  0.26910233]
 [0.29093027 0.7090697 ]
 [0.26912898 0.730871  ]
 [0.7301893  0.26981068]
 [0.48715928 0.51284075]
 [0.26923364 0.73076636]
 [0.27229205 0.7277079 ]
 [0.26894873 0.73105127]
 [0.26955223 0.7304478 ]
 [0.2690097  0.7309903 ]
 [0.73105824 0.2689418 ]
 [0.72749686 0.27250314]
 [0.26896045 0.73103946]
 [0.26894215 0.7310578 ]
 [0.2690959  0.7309041 ]
 [0.2689638  0.7310362 ]
 [0.26897585 0.73102415]
 [0.30804124 0.6919587 ]
 [0.2690198  0.73098016]
 [0.26951998 0.7304801 ]
 [0.2689426  0.7310574 ]
 [0.26896107 0.731039  ]
 [0.2689431  0.7310569 ]
 [0.7310567  0.2689433 ]
 [0.73105824 0.26894173]
 [0.557228   0.4427719 ]
 [0.27002597 0.72997403]
 [0.7278676  0.2721324 ]
 [0.71627456 0.28372547]
 [0.26903558 0.7309645 ]]

Prediction alterne entre ~27 et ~73 avec quelques ~0.5
raisons possible:

mauvais import des images/labels qui fausse le tout and|or
les predictions se ressemblement simplement car les images sont similaires...(voir d'autres output de model de dl) and|or
les variables need tuning peut-être que le weight_loss se bloque... and|or
autres raisons pour l'instant inconnu
